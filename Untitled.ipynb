{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab89b63-861a-49b7-9542-8147a9f0e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Linear(in_features=32000, out_features=512, bias=False)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wk): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wv): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (wo): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=512, out_features=1376, bias=False)\n",
       "        (w2): Linear(in_features=1376, out_features=512, bias=False)\n",
       "        (w3): Linear(in_features=512, out_features=1376, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=512, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import ModelArgs, Transformer\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "use_mps = True\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "out_dir = 'out' # ignored if init_from is not 'resume'\n",
    "start = \"\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 1 # number of samples to draw\n",
    "max_new_tokens = 100 # number of tokens generated in each sample\n",
    "temperature = 1.0 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 300 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() and use_mps else 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "#dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "dtype = \"float32\"\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "#exec(open('configurator.py').read()) # overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class Hook:\n",
    "    def __init__(self):\n",
    "        self.clear()\n",
    "        \n",
    "    def __call__(self, layer_name, layer_id, activation):\n",
    "        self.activations[f\"{layer_name}.{layer_id}\"] = activation\n",
    "\n",
    "    def clear(self):\n",
    "        self.activations = {}\n",
    "\n",
    "\n",
    "\n",
    "hook = Hook()\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'mps' if 'mps' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type != 'cuda' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "ckpt_path = os.path.join(out_dir, 'stories42M.pt')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = ModelArgs(**checkpoint['model_args'])\n",
    "model = Transformer(gptconf, hook)\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    # if k == \"tok_embeddings.weight\":\n",
    "    #     print(k, v.shape)\n",
    "    #     state_dict[k] = v.transpose(1, 0)\n",
    "    #     print(state_dict[k].shape)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81514554-8762-4b66-a257-00781226403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4176ed2b-4267-4e9c-a801-23b58c824bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a big, red bus. The bus was very good at its job. The bus liked to help people get to places where they needed to go.\n",
      "One day, the bus met a little boy named Tim. Tim wanted to go to the park to feed his dog. The bus said, \"Okay, I will take you to the park to feed your dog.\" Tim was very happy because the bus was a dependable friend.\n",
      "After Tim fed his\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "model.hook = lambda x, y, z: None\n",
    "start_ids = enc.encode(\"\", bos=True, eos=False)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=1.0, top_k=top_k)\n",
    "            print(enc.decode(y[0].tolist()))\n",
    "            print('---------------')\n",
    "model.hook = hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a6816-b765-47ae-878e-199430053174",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"! ! ! ! ! ! ! ! ! ! ! !\"\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = enc.encode(start, bos=True, eos=False)\n",
    "print(start_ids)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5fdf3-a976-4571-8130-9fa476b180ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.encode(\"computer\", bos=False, eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ac871-b385-4143-83fe-1c2613b69ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c332727-52bf-4206-9b76-e62cfee60681",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_free_tokens = len(start_ids) - 1 #30\n",
    "# num_free_tokens = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e6219-2f7d-45d3-ba06-d224174a2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_ids = start_ids + [1738]*num_free_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a3e9-aa36-49e3-b48a-ca1447083b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284b0cf-95f4-4f4f-a5ff-3947d362451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x_idx, x, logits, activations, print_loss=True):\n",
    "    act = activations[\"ffn.5\"][:, -1, 32]\n",
    "    L = act\n",
    "\n",
    "    # logits = logits[:, :-1].clone()\n",
    "    # x_idx = x_idx[:, 1:].clone()\n",
    "    \n",
    "    # log_p = -torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), x_idx.view(-1))\n",
    "    # alpha = 0.0\n",
    "    # beta = 1.0\n",
    "    # return alpha * L + beta * log_p\n",
    "    # return L\n",
    "    # \n",
    "\n",
    "    logits = logits[:, -num_free_tokens-1:-1]\n",
    "    \n",
    "    probs = torch.log_softmax(logits, dim=-1)\n",
    "    x = x[:, -num_free_tokens:]\n",
    "\n",
    "    # print(x.shape)\n",
    "    \n",
    "    p = torch.sum(probs * x, dim=-1).sum(-1)\n",
    "    # print(p.shape)\n",
    "\n",
    "    # if print_loss:\n",
    "        # print(f\"L = {L.item()}\")\n",
    "        # print(f\"p = {p.item()}\")\n",
    "    \n",
    "    return 0.02 * p + L, p, L\n",
    "    # return L\n",
    "    # return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d3702-15f5-40b7-bbb3-8bf2a7e89d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0a96-889b-49ac-8963-9dcbffd44124",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, p_losses, L_losses = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7659dfd-64e9-4b3f-a13a-71cadc3696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "# num_free_tokens = 30\n",
    "batch_size = 50\n",
    "\n",
    "assert batch_size <= num_free_tokens * top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23437800-8e93-4c19-a668-dd1d0e3e8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for i in range(1000):\n",
    "    model.train()\n",
    "    \n",
    "    # print(f\"iter {i}\")\n",
    "    # print(start_ids)\n",
    "    \n",
    "    x_idx = torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...]\n",
    "    x = torch.nn.functional.one_hot(x_idx, num_classes=model.params.vocab_size).float()\n",
    "    \n",
    "    x.requires_grad = True\n",
    "\n",
    "    hook.clear()\n",
    "    logits = model(x, x_idx)\n",
    "    activations = hook.activations\n",
    "    hook.clear()\n",
    "    \n",
    "    l, p_loss, L_loss = loss(x_idx, x, logits, activations)\n",
    "\n",
    "    losses.append(l.item())\n",
    "    p_losses.append(p_loss.item())\n",
    "    L_losses.append(L_loss.item())\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.set_size_inches(15, 10)\n",
    "    axs[0, 0].plot(losses)\n",
    "    axs[0, 0].set_title(\"Objective\")\n",
    "\n",
    "    axs[0, 1].plot(p_losses)\n",
    "    axs[0, 1].set_title(\"Likelihood\")\n",
    "\n",
    "    axs[1, 0].plot(L_losses)\n",
    "    axs[1, 0].set_title(\"Activation\")\n",
    "    plt.show()\n",
    "\n",
    "    print(enc.decode(start_ids))\n",
    "    print(f\"objective = {l.item()}\")\n",
    "\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "    # log_probs = torch.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # logits_cont = logits[:, -(len(continuation_enc)+1):-1]\n",
    "    # print(logits_cont.shape)\n",
    "    # l = -torch.nn.functional.cross_entropy(logits_cont.view(-1, logits_cont.size(-1)), continuation_tensor.view(-1))\n",
    "    \n",
    "    l.backward()\n",
    "\n",
    "    replacement_tokens = []\n",
    "    for t in range(1, num_free_tokens + 1):\n",
    "        _, top_k_indices = torch.topk(x.grad[0, -t], top_k)\n",
    "        # print(top_k_indices)\n",
    "        # print(logits[0, -t].argmax())\n",
    "        for ik in top_k_indices:\n",
    "            replacement_tokens.append((t, ik.item()))\n",
    "\n",
    "    random.shuffle(replacement_tokens)\n",
    "\n",
    "    batch = []\n",
    "    for t, new_token in replacement_tokens[:batch_size]:\n",
    "        start_ids_repl = start_ids.copy()\n",
    "        start_ids_repl[-t] = new_token\n",
    "        batch.append(start_ids_repl)\n",
    "\n",
    "    \n",
    "    x_repl_idx = torch.tensor(batch, dtype=torch.long, device=device)\n",
    "    x_repl = torch.nn.functional.one_hot(x_repl_idx, num_classes=model.params.vocab_size).float()\n",
    "\n",
    "    # max_obj = -1e9\n",
    "    max_obj = l[0].item()\n",
    "    best_replacement = None\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        hook.clear()\n",
    "        logits = model(x_repl, x_repl_idx)\n",
    "        activations = hook.activations\n",
    "        hook.clear()\n",
    "        \n",
    "        l1, _, _ = loss(x_repl_idx, x_repl, logits, activations, print_loss=False)\n",
    "        \n",
    "        # logits_cont = logits[:, -(len(continuation_enc)+1):-1]\n",
    "        # print(logits_cont.shape)\n",
    "        # print(logits_cont.argmax())\n",
    "        best_loss, best_index = torch.max(l1, dim=0)\n",
    "        # if best_loss.item() > l[0].item():\n",
    "        best_replacement = replacement_tokens[best_index.item()]\n",
    "        # for i in range(batch_size):\n",
    "        #     loss_i = l1[i].item()\n",
    "        #     if loss_i > max_obj:\n",
    "        #         best_replacement = replacement_tokens[i]\n",
    "        #         max_obj = loss_i\n",
    "\n",
    "    # print(f\"max_obj = {max_obj}\")\n",
    "\n",
    "    if best_replacement is not None:\n",
    "        # print(\"replacing\", best_replacement, best_loss)\n",
    "        best_t, best_token = best_replacement\n",
    "        start_ids[-best_t] = best_token\n",
    "    # else:\n",
    "        # print(\"replacing none\")\n",
    "        \n",
    "    model.zero_grad()\n",
    "\n",
    "    \n",
    "    \n",
    "    # print(max_token)\n",
    "    # print(enc.decode([max_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e19e9-6795-4d0a-a186-4ef6d45af5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "#run generation\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=0.0, top_k=top_k)\n",
    "            print(enc.decode(y[0].tolist()))\n",
    "            print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465edf6-07cd-49fa-8db5-d1162fea5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40539ac6-efa7-41d8-8c05-9f940f98f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_onehot = torch.nn.functional.one_hot(x, num_classes=model.params.vocab_size).float()\n",
    "    logits = model(x_onehot, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "4ae93e3e-8c2a-4357-8654-8aeda921a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 32000])"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "f5999f5e-7832-4f80-8bfc-8e2a56920e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.5858, 0.0666, 0.0427, 0.0418, 0.0324]], device='mps:0'),\n",
       "indices=tensor([[1260,  372, 1183,  540,  310]], device='mps:0'))"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.softmax(logits[:, -1], axis=-1), axis=-1, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "39da6c72-c14d-431b-884c-4242a0fe1490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, device='mps:0')"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(logits[:, -1], axis=-1)[0, 1260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4697a384-89a9-45c8-89d0-bd4529d231f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(368)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0, -1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28edb564-670f-4cf1-9cf0-b0ffde41b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "efe43252-369f-47cf-8a7f-41501281f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.log(probs[0, -1, 7870])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9209592c-8855-4bf9-a8e9-ac05ff0de26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32000])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3c46448e-b813-4084-ac4a-1af10d326ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b31566f9-645b-4759-a544-b2f5ab99403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7334)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.grad[0, -1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9a8a0921-6acf-4457-8ffd-332a0db69b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([9.7334, 8.6131, 8.1965, 7.7321, 7.2178]),\n",
       "indices=tensor([  611,   509, 20285,  1557,  2233]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(x.grad[0, -1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4da92d-7f13-40af-928f-87bf9800dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7870]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"Tim\", bos=False,eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0eb7372f-4aed-4ca8-80c7-b2d86ac35dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ma'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([611])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d54d7c-56d0-4f79-90f8-93c8c90d6adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
